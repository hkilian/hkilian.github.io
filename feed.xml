<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.7.2">Jekyll</generator><link href="/feed.xml" rel="self" type="application/atom+xml" /><link href="/" rel="alternate" type="text/html" /><updated>2018-01-27T23:24:56+00:00</updated><id>/</id><title type="html">Harry Kilian</title><subtitle>Personal blog to post experiments.</subtitle><entry><title type="html">From Wordpress to Jekyll</title><link href="/jekyll/2018/01/26/From-wordpress-to-Jekyll.html" rel="alternate" type="text/html" title="From Wordpress to Jekyll" /><published>2018-01-26T21:18:37+00:00</published><updated>2018-01-26T21:18:37+00:00</updated><id>/jekyll/2018/01/26/From%20wordpress%20to%20Jekyll</id><content type="html" xml:base="/jekyll/2018/01/26/From-wordpress-to-Jekyll.html">&lt;p&gt;Decided to move the blog from &lt;a href=&quot;wordpress.com&quot;&gt;wordpress.com&lt;/a&gt; managed hosting over to github.io pages using the &lt;a href=&quot;https://jekyllrb.com/&quot;&gt;jekyll&lt;/a&gt; static site generator.
My primary motivation was that I want to be able to embed any content on the blog, perhaps some canvas/opengl stuff in the future.
I could have gone the self-hosted wordpress route but of course you have to pay a hosting fee and there is set-up involved in doing that.&lt;/p&gt;

&lt;p&gt;So far I’m really impressed with github.io, all you need to do is setup a git repo and push any .html file, and right away you have a functioning site.
There are limitations, you cant have database or any server-side scripting, but for a normal blog type website like I’m running it serves just fine. 
Best of all its free.&lt;/p&gt;

&lt;p&gt;My only complaint so far is with the &lt;a href=&quot;https://jekyllrb.com/&quot;&gt;jekyll&lt;/a&gt; migration process. It provides a migration solution for wordpress.com sites however the html in dumped in the &lt;code class=&quot;highlighter-rouge&quot;&gt;/_posts&lt;/code&gt;
folder where all posts reside, was pretty rubbish. Not in markdown format and showed weird metadata above each post, also it didnt copy over images in galleries or anything like that. 
I had to go through and fix them up, and in the end I just opted to make .markdown files out of each one, which did take a while.&lt;/p&gt;

&lt;p&gt;Overall I’m pretty excited to start blogging again. I’m hoping to embed some cool graphics experiments in the blog and play around with demoing some c++ with emscripten.&lt;/p&gt;

&lt;h3 id=&quot;update&quot;&gt;Update&lt;/h3&gt;

&lt;p&gt;I have since learnt that github pages only supports a very limited number of jekyll plugins. Not only that but the error reporting for failed builds is not so great. 
Took quite a bit of searching around before I realised that a youtube plug-in was causing the build work fine locally but fail on github.
A solution is to build all the files locally with the needed plugins and then just send output .html files to the remote repo.&lt;/p&gt;

&lt;h3 id=&quot;update-2&quot;&gt;Update 2&lt;/h3&gt;

&lt;p&gt;I’ve now got the site working with my jekyll plugins. The solution was to have 2 git repos. One which had the jekyll markdown files and another which only has the html output 
from jekyll. Basically I build the site myself and send just the html files to github.&lt;/p&gt;</content><author><name></name></author><summary type="html">Decided to move the blog from wordpress.com managed hosting over to github.io pages using the jekyll static site generator. My primary motivation was that I want to be able to embed any content on the blog, perhaps some canvas/opengl stuff in the future. I could have gone the self-hosted wordpress route but of course you have to pay a hosting fee and there is set-up involved in doing that.</summary></entry><entry><title type="html">Progress 17: Depth, Volumes and CPU Picking</title><link href="/progress/2017/05/31/progress-17-volumes-cpu-picking2.html" rel="alternate" type="text/html" title="Progress 17: Depth, Volumes and CPU Picking" /><published>2017-05-31T07:34:53+01:00</published><updated>2017-05-31T07:34:53+01:00</updated><id>/progress/2017/05/31/progress-17-volumes-cpu-picking2</id><content type="html" xml:base="/progress/2017/05/31/progress-17-volumes-cpu-picking2.html">&lt;h2 id=&quot;landscapedepth&quot;&gt;Landscape Depth&lt;/h2&gt;
&lt;p&gt;The landscape now has information in the Y axis(downward), as you dig the tiles change from soil to stone to granite. It’s kept quite simple at the moment but later I want to add further noise manipulation into the algorithm so that the player can find pockets of different types of rock as they dig.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/screenshot_mon_may_29_00_18_50_2017.png&quot; alt=&quot;screenshot&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;excavation-tool&quot;&gt;Excavation Tool&lt;/h2&gt;
&lt;p&gt;I made some progress on creating tools which the player can use to manipulate the landscape. The excavation tool allows a player to select a rectangular region to dig downward on. At the moment the excavation is done instantly but later it will be dug out by players game units.&lt;/p&gt;

&lt;h2 id=&quot;volumes&quot;&gt;Volumes&lt;/h2&gt;
&lt;p&gt;I’ve added rudimentary support for voxel volumes.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/screenshot_tue_may_30_18_28_47_2017.png&quot; alt=&quot;screenshot&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;cpu-picking&quot;&gt;CPU Picking&lt;/h2&gt;
&lt;p&gt;I had wrote before about GPU picking which worked reasonably well as a temp solution. However the problem is that because the cpu is just reading the positions buffer on gpu, you can’t pick any locations that are not visible on screen. As I was using the excavation tool this became problematic and made the tool unintuitive. Not only that, on my old and useless macbook pro the PBO(pixel buffer object) was still stalling the cpu despite PBO’s being non blocking. The new solution involves casting a ray from the camera through the terrain and calculating where there is an intersection. Works a treat, don’t know why I didn’t just do this before really.&lt;/p&gt;

&lt;h2 id=&quot;other-additionschanges&quot;&gt;Other Additions/Changes&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;Refactored the worldgen noise sampler.&lt;/li&gt;
  &lt;li&gt;Refactored the precipice mesh generator&lt;/li&gt;
  &lt;li&gt;Fixed a bug where the world tiles were actually be rendered mirrored on the Z axis.&lt;/li&gt;
  &lt;li&gt;Fixed the camera fog distance from showing unrendered geometry when zoomed in.&lt;/li&gt;
  &lt;li&gt;Oncreen nodes now hold a component which links to the underlying world object.&lt;/li&gt;
&lt;/ul&gt;</content><author><name></name></author><summary type="html">Landscape Depth The landscape now has information in the Y axis(downward), as you dig the tiles change from soil to stone to granite. It’s kept quite simple at the moment but later I want to add further noise manipulation into the algorithm so that the player can find pockets of different types of rock as they dig.</summary></entry><entry><title type="html">Update 16: AO, Trees and the Perspective Camera</title><link href="/graphics/progress/2017/05/20/update-16-ao-and-perspective-cameras.html" rel="alternate" type="text/html" title="Update 16: AO, Trees and the Perspective Camera" /><published>2017-05-20T12:52:47+01:00</published><updated>2017-05-20T12:52:47+01:00</updated><id>/graphics/progress/2017/05/20/update-16-ao-and-perspective-cameras</id><content type="html" xml:base="/graphics/progress/2017/05/20/update-16-ao-and-perspective-cameras.html">&lt;h2 id=&quot;orthographic-vs-perspective&quot;&gt;Orthographic vs Perspective&lt;/h2&gt;
&lt;p&gt;Up until now I’ve had the game camera set up as an &lt;a href=&quot;https://en.wikipedia.org/wiki/Orthographic_projection&quot;&gt;orthographic projection&lt;/a&gt;. Which gives a similar style to an isometric game but in 3D. I went for this initially because I wanted it to be reminiscent of games like &lt;a href=&quot;https://en.wikipedia.org/wiki/Age_of_Empires&quot;&gt;Age Of Empires&lt;/a&gt; and &lt;a href=&quot;https://en.wikipedia.org/wiki/RollerCoaster_Tycoon&quot;&gt;RCT&lt;/a&gt;. It wasn’t until I started working on the construction tools that I realised how it was becoming difficult to visually understand the terrain and where to place objects. It really doesnt work all that well. Because orthographic cameras have a fixed depth you essentially lose some important information regarding the position and shape of the 3D objects. It makes them slightly harder to understand and also makes it difficult to judge distances in the game world. Games like &lt;a href=&quot;https://en.wikipedia.org/wiki/Monument_Valley_(video_game)&quot;&gt;Monument Valley&lt;/a&gt; take advantage of this to create optical illusions and interesting puzzles. For this game though, I don’t want illusions, the most important thing is that the player can understand quickly what is happening in the game.&lt;/p&gt;

&lt;p&gt;A slight problem with using perspective camera is that the method for &lt;a href=&quot;/graphics/progress/2017/02/17/update-8-grass-rendering.html&quot;&gt;grass rendering&lt;/a&gt; I was using did not work as well. As I was using shell rendering It only looks decent when looking downward on the world, with a perspective camera it just didn’t work. Rendering the grass that way was quite costly anyhow, so I had no problem removing it.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/screenshot_sat_may_20_13_49_52_2017.png&quot; alt=&quot;screenshot&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;daynightcycle&quot;&gt;Day/Night Cycle&lt;/h2&gt;
&lt;p&gt;I put a little time into getting a working visible day and night cycle. In free floating camera mode you can see the sun in the sky at the correct position. The sky itself now changes color according to the time of day, so for example it will turn orange near sunset. At night the distance fog is changed to give some atmosphere. At night time the focal point of the camera emits light, this makes it so you can still see the surrounding area as well as giving an eerie atmosphere.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/day-night-cycle.png&quot; alt=&quot;screenshot&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;ambient-occlusion&quot;&gt;Ambient Occlusion&lt;/h2&gt;

&lt;p&gt;I wrote last update about &lt;a href=&quot;/graphics/progress/2017/05/10/update-15-ao-experiments.html&quot;&gt;screen space ambient occlusion&lt;/a&gt; and how the performance hit was too large to justify the effect. I’ve been playing around with some other methods with some success. I can’t bake occlusion into the mesh because the terrain itself is actually just a &lt;a href=&quot;https://en.wikipedia.org/wiki/Displacement_mapping&quot;&gt;displacement map&lt;/a&gt;. What I thought of doing however is to calculate the AO by sampling the adjacent pixels from within the displace map for each vertex. You can see the results in the day/night pictures above.&lt;/p&gt;

&lt;h2 id=&quot;trees&quot;&gt;Trees&lt;/h2&gt;
&lt;p&gt;A bit of time was put into the ECS which will manage all the world objects. I put together a placeholder tree model and spawned 10,000 of them around the map. The viewing distance for the trees is not to great in floating camera mode but in normal construction mode It works fine.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/screenshot_sat_may_20_14_55_07_2017.png&quot; alt=&quot;screenshot&quot; /&gt;&lt;/p&gt;</content><author><name></name></author><summary type="html">Orthographic vs Perspective Up until now I’ve had the game camera set up as an orthographic projection. Which gives a similar style to an isometric game but in 3D. I went for this initially because I wanted it to be reminiscent of games like Age Of Empires and RCT. It wasn’t until I started working on the construction tools that I realised how it was becoming difficult to visually understand the terrain and where to place objects. It really doesnt work all that well. Because orthographic cameras have a fixed depth you essentially lose some important information regarding the position and shape of the 3D objects. It makes them slightly harder to understand and also makes it difficult to judge distances in the game world. Games like Monument Valley take advantage of this to create optical illusions and interesting puzzles. For this game though, I don’t want illusions, the most important thing is that the player can understand quickly what is happening in the game.</summary></entry><entry><title type="html">Update 15: SSAO Experiments</title><link href="/graphics/progress/2017/05/10/update-15-ao-experiments.html" rel="alternate" type="text/html" title="Update 15: SSAO Experiments" /><published>2017-05-10T19:09:04+01:00</published><updated>2017-05-10T19:09:04+01:00</updated><id>/graphics/progress/2017/05/10/update-15-ao-experiments</id><content type="html" xml:base="/graphics/progress/2017/05/10/update-15-ao-experiments.html">&lt;h2 id=&quot;screen-space-ambient-occlusion&quot;&gt;Screen Space Ambient Occlusion&lt;/h2&gt;

&lt;p&gt;Small update this time. I have started working a day job again and so haven’t spent much time on the game. For a bit of fun I’ve been thinking about implementing screen space ambient occlusion, something I haven’t written before. As I’ve been developing and experimenting with the game I’ve noticed issues with my eye being unable identify height and depth of the tiles. Often 2 tiles will sit at different heights but the same orientation, meaning they will be lit exactly the same. Take a look at this example.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/screenshot_sat_may__6_14_17_47_2017.png&quot; alt=&quot;screenshot&quot; /&gt;&lt;/p&gt;

&lt;p&gt;The tile in middle is shaded the same as the tile behind. While it’s not difficult to understand what tile is where, It really shouldnt require any thinking. To solve this I started looking into ambient occlusion techniques, I had a form of AO in the game before using an AO value baked into the terrain verts. However, Now I have redone the terrain mesh system making that no longer an attractive option. The most common AO in games is SSAO (Screen Space Ambient Occlusion), there are different implementations but essentially you would use the positions and normals buffer to sample surrounding pixels and calculate if they occlude the current pixels.&lt;/p&gt;

&lt;p&gt;I put together a shader which does just that. The results are decent however there is a significant performance hit. I’m using a half size AO buffer and 16 samples, then a 4x4 blur. Framerate goes from about 160 to just about keeping up at 60. I’m sure I could optimize further and improve the method, however I have played round tweaking parameter and even at high sample counts the results are not that great. I think I am going to take another look at baked AO.&lt;/p&gt;

&lt;p&gt;Before
&lt;img src=&quot;/assets/screenshot_sat_may__6_13_31_49_2017.png&quot; alt=&quot;screenshot&quot; /&gt;&lt;/p&gt;

&lt;p&gt;After
&lt;img src=&quot;/assets/screenshot_sat_may__6_13_31_40_2017.png&quot; alt=&quot;screenshot&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;other-changes&quot;&gt;Other changes:&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;Added a way to recompile shaders at runtime so I can make modifications to shader code and see results instantly (Very useful, should have done this ages ago!)&lt;/li&gt;
  &lt;li&gt;Improved pipeline for adding 3d models.&lt;/li&gt;
  &lt;li&gt;Made headway on ECS for managing game objects.&lt;/li&gt;
&lt;/ul&gt;</content><author><name></name></author><summary type="html">Screen Space Ambient Occlusion</summary></entry><entry><title type="html">Update 14: Minor Improvements</title><link href="/graphics/progress/2017/04/30/update-14-minor-improvements.html" rel="alternate" type="text/html" title="Update 14: Minor Improvements" /><published>2017-04-30T08:52:38+01:00</published><updated>2017-04-30T08:52:38+01:00</updated><id>/graphics/progress/2017/04/30/update-14-minor-improvements</id><content type="html" xml:base="/graphics/progress/2017/04/30/update-14-minor-improvements.html">&lt;p&gt;Nothing too major this update, I’ve been working on some other personal things the last month so I haven’t done anything major on the game.&lt;/p&gt;

&lt;h2 id=&quot;updates&quot;&gt;Updates&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;Made it so an individual tile will highlight when hovered over with the mouse.&lt;/li&gt;
  &lt;li&gt;You can now make square box selections with the mouse by clicking and dragging.&lt;/li&gt;
  &lt;li&gt;Added a distance fog for when using the free floating camera&lt;/li&gt;
  &lt;li&gt;Replaced black sky color with blue.&lt;/li&gt;
  &lt;li&gt;Fixed a z-clipping issue where the ocean mesh intersected the land mesh.&lt;/li&gt;
  &lt;li&gt;Optimized terrain rendering for free floating camera. Camera used to sit in the middle of the terrain chunk, now any terrain behind the camera is not calculated.&lt;/li&gt;
  &lt;li&gt;Shaders now recompile when using free floating camera and implement a different type of z-buffer.&lt;/li&gt;
  &lt;li&gt;In debug mode I can now switch from game camera to free floating camera at click of a button.&lt;/li&gt;
  &lt;li&gt;Added more robust terrain tile painting tools&lt;/li&gt;
  &lt;li&gt;When a grass tile is sloped above a certain threshold it becomes a dirt tile.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;pictures&quot;&gt;Pictures&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;/assets/screenshot_sat_apr_29_19_48_20_2017.png&quot; alt=&quot;screenshot&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/screenshot_sat_apr_29_18_49_34_2017.png&quot; alt=&quot;screenshot&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/screenshot_sat_apr_29_23_18_34_2017.png&quot; alt=&quot;screenshot&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;flyover-video&quot;&gt;Flyover Video&lt;/h2&gt;
&lt;p&gt;Here is a low framerate fly over of the terrain using the free floating camera.&lt;/p&gt;

&lt;iframe width=&quot;800&quot; height=&quot;500&quot; frameborder=&quot;0&quot; src=&quot;http://www.youtube.com/embed/oKoOe-aLpTA?color=white&amp;amp;theme=light&quot;&gt;&lt;/iframe&gt;</content><author><name></name></author><summary type="html">Nothing too major this update, I’ve been working on some other personal things the last month so I haven’t done anything major on the game.</summary></entry><entry><title type="html">Update 13: Simple Rivers</title><link href="/graphics/procedural/progress/2017/04/29/update-12-simple-rivers.html" rel="alternate" type="text/html" title="Update 13: Simple Rivers" /><published>2017-04-29T12:11:28+01:00</published><updated>2017-04-29T12:11:28+01:00</updated><id>/graphics/procedural/progress/2017/04/29/update-12-simple-rivers</id><content type="html" xml:base="/graphics/procedural/progress/2017/04/29/update-12-simple-rivers.html">&lt;p&gt;For me, one of the most important parts of the world generation has to be the rivers. I feel like I rarely see genuine flowing rivers in games, especially not procedurally generated ones. Minecraft and NoMansSky have ‘rivers’ but they don’t really follow any logic, they don’t really flow, and have no clear end and start. This is because the world of minecraft is on an infinite plane and NoMansSky has infinite planets. The terrain has no hard limits, so it’s not possible to do an actual simulation of erosion or rainfall. For me, rivers created from noise generation just don’t cut it, even a very simple simulation of rainfall and erosion is much more interesting.&lt;/p&gt;

&lt;p&gt;I always like to get something working as soon as possible. So I started with a dead simple rainfall model. I attach a ‘water level’ value to each tile, then to simulate rain I increment the ‘water level’ for each tile every step of the simulation. Higher points will get slightly more rain. Then, if the water level on an adjacent tile is lower, I move a fraction of water from the current tile to that adjacent tile. I also evaporate water on each tile by a constant amount each step.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/screenshot_sat_mar_18_20_28_26_2017.png&quot; alt=&quot;screenshot&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Initial results are quite decent, the noise generation already has decent river like formations and valleys carved into it. So the water just flows into the valleys and looks quite natural.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/screenshot_sat_mar_18_18_07_04_2017.png&quot; alt=&quot;screenshot&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Simple beginnings, next step will be to add an erosion model and actually mesh the rivers. Right now, any tile that’s above a water threshold is blue, there is no depth to water, it’s just flat.&lt;/p&gt;</content><author><name></name></author><category term="rivers" /><category term="simulation" /><category term="water" /><summary type="html">For me, one of the most important parts of the world generation has to be the rivers. I feel like I rarely see genuine flowing rivers in games, especially not procedurally generated ones. Minecraft and NoMansSky have ‘rivers’ but they don’t really follow any logic, they don’t really flow, and have no clear end and start. This is because the world of minecraft is on an infinite plane and NoMansSky has infinite planets. The terrain has no hard limits, so it’s not possible to do an actual simulation of erosion or rainfall. For me, rivers created from noise generation just don’t cut it, even a very simple simulation of rainfall and erosion is much more interesting.</summary></entry><entry><title type="html">Update 12: Terrain Generation Experiments</title><link href="/graphics/procedural/progress/2017/03/16/update-12-terrain-generation-experiments.html" rel="alternate" type="text/html" title="Update 12: Terrain Generation Experiments" /><published>2017-03-16T14:57:11+00:00</published><updated>2017-03-16T14:57:11+00:00</updated><id>/graphics/procedural/progress/2017/03/16/update-12-terrain-generation-experiments</id><content type="html" xml:base="/graphics/procedural/progress/2017/03/16/update-12-terrain-generation-experiments.html">&lt;p&gt;I talked before about the &lt;a href=&quot;/procedural/progress/2017/03/14/update-11-world-generation-refactor.html&quot;&gt;improved noise system&lt;/a&gt;. I’ve been playing around and experimenting with different parameters, getting some interesting results. The difference between a real island and my fake video game island is that of scale. I want mountains, sweeping rivers, wildly different biomes, all on one island that spans maybe only 1.5 miles coast to coast. So it wouldn’t make sense for my islands to perfectly imitate the natural forming islands of earth. I wouldn’t say the terrain of the islands below look realistic, however these islands might not have even been created using the same tectonic processes. I’ve thought a bit about how far a fantasy world can really deviate from the real world. I think, that If the world looks like it was formed by some sort of natural process then it gets a pass. The real question is weather these maps are fun to play and build on. They definitely provide some nice variation across seeds with each map having some distinctive features.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/terrain-gen-4-tiles.png&quot; alt=&quot;4 different seeds&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;changing-lacunarity&quot;&gt;Changing lacunarity&lt;/h2&gt;
&lt;p&gt;Below I’ve demonstrated the effect of changing lacunarity on an FBM noise which acts as an input to the frequency of a Ridged Multi noise. So thats one set of noise acting as an input on another noise. Lacunarity starts at 0.0 and increments by 0.1 to a final value of 2.5.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/set1272-1.png&quot; alt=&quot;Effect of changing lacunarity&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;changing-frequency&quot;&gt;Changing frequency&lt;/h2&gt;
&lt;p&gt;Below you can see the effect of changing the frequency of the input noise.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/set2416.png&quot; alt=&quot;Effect of changing lacunarity&quot; /&gt;&lt;/p&gt;

&lt;p&gt;The problem with this noise generation is that quite often I get a dud seed, especially when using noise of lower frequency. Sometimes an island will be very small, or overly large. I’m thinking of writing a function which discards maps based on total landmass, then keeps trying new maps until it finds a good fit. I would only need to sample the noise few times, maybe 200 samples, to get a reasonably accurate landmass approximation.&lt;/p&gt;

&lt;h2 id=&quot;changing-intensity&quot;&gt;Changing intensity&lt;/h2&gt;
&lt;p&gt;Below is the effect of changing intensity on the input noise. It starts as a sphere because there is a radial gradient subtracted from the noise to act as a falloff. With our input noise having 0 intensity it means that the main noise has a frequency of 0, the noise becomes just a flat color.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/set4752.png&quot; alt=&quot;Effect of changing lacunarity&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/set4216.png&quot; alt=&quot;Effect of changing lacunarity&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/image-3496.png&quot; alt=&quot;Effect of changing lacunarity&quot; /&gt;&lt;/p&gt;</content><author><name></name></author><summary type="html">I talked before about the improved noise system. I’ve been playing around and experimenting with different parameters, getting some interesting results. The difference between a real island and my fake video game island is that of scale. I want mountains, sweeping rivers, wildly different biomes, all on one island that spans maybe only 1.5 miles coast to coast. So it wouldn’t make sense for my islands to perfectly imitate the natural forming islands of earth. I wouldn’t say the terrain of the islands below look realistic, however these islands might not have even been created using the same tectonic processes. I’ve thought a bit about how far a fantasy world can really deviate from the real world. I think, that If the world looks like it was formed by some sort of natural process then it gets a pass. The real question is weather these maps are fun to play and build on. They definitely provide some nice variation across seeds with each map having some distinctive features.</summary></entry><entry><title type="html">Update 11: World Generation Refactor</title><link href="/procedural/progress/2017/03/14/update-11-world-generation-refactor.html" rel="alternate" type="text/html" title="Update 11: World Generation Refactor" /><published>2017-03-14T14:31:26+00:00</published><updated>2017-03-14T14:31:26+00:00</updated><id>/procedural/progress/2017/03/14/update-11-world-generation-refactor</id><content type="html" xml:base="/procedural/progress/2017/03/14/update-11-world-generation-refactor.html">&lt;p&gt;I’ve spent some time refactoring the world generation and building a useful world generation editor. I think having an actual visual interface to preview the generation in real time will be massively useful. Before, I would make changes to the algorithm in c++, then have to wait while it compiles and launches to see the changes. This is obviously painfully slow and make makes it very difficult to experiment. Now I can manipulate noise parameters in a custom editor and see the changes right away.&lt;/p&gt;

&lt;h2 id=&quot;noise&quot;&gt;Noise&lt;/h2&gt;
&lt;p&gt;Before, all I could do with noise was stack them on top of each other with a blending function (Add, Subtract, Avg, Multiply..). However to get more exciting results the noise parameters need to be deviated by another noise value. So for example, now I can plug ‘Billow’ noise into the frequency parameter of an ‘FBM ‘noise. This kind of perturbation can get really interesting results.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/image-5238.png&quot; alt=&quot;screenshot&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/image-4873.png&quot; alt=&quot;screenshot&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/image-3671.png&quot; alt=&quot;screenshot&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;biomes&quot;&gt;Biomes&lt;/h2&gt;
&lt;p&gt;In all but the first post I ever made on the game you can’t see any biomes on the map. I actually disabled biomes because of a bug in the code. I’ve gone and fixed the bug and tweaked the whole biome generation system. I also wrote a script which takes the current world generation parameters and outputs one large image containg lots of maps using different seeds.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/set3.png&quot; alt=&quot;screenshot&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/seeds.png&quot; alt=&quot;screenshot&quot; /&gt;&lt;/p&gt;

&lt;p&gt;These maps above are using the old noise system. The mountains are just kind of splatted on top of the base noise. Next step will be to play around with the new noise system to create more natural looking mountains which blend into the terrain.&lt;/p&gt;</content><author><name></name></author><summary type="html">I’ve spent some time refactoring the world generation and building a useful world generation editor. I think having an actual visual interface to preview the generation in real time will be massively useful. Before, I would make changes to the algorithm in c++, then have to wait while it compiles and launches to see the changes. This is obviously painfully slow and make makes it very difficult to experiment. Now I can manipulate noise parameters in a custom editor and see the changes right away.</summary></entry><entry><title type="html">Procedural Planets</title><link href="/graphics/procedural/2017/03/07/procedural-planets.html" rel="alternate" type="text/html" title="Procedural Planets" /><published>2017-03-07T17:35:15+00:00</published><updated>2017-03-07T17:35:15+00:00</updated><id>/graphics/procedural/2017/03/07/procedural-planets</id><content type="html" xml:base="/graphics/procedural/2017/03/07/procedural-planets.html">&lt;p&gt;I put together a little planet generator a few months ago, thought I would share. The generation is based on several parameters like temperature(distance to sun), size, population etc… then it churns out these neat little pixel art planets. Pretty simple but a cool result, this was done in Unity3D.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/planet1.png&quot; alt=&quot;screenshot&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/planet2.png&quot; alt=&quot;screenshot&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/planet3.png&quot; alt=&quot;screenshot&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/planet5.png&quot; alt=&quot;screenshot&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/6.png&quot; alt=&quot;screenshot&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/7.png&quot; alt=&quot;screenshot&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/8.png&quot; alt=&quot;screenshot&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/9.png&quot; alt=&quot;screenshot&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/10.png&quot; alt=&quot;screenshot&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/11.png&quot; alt=&quot;screenshot&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/12.png&quot; alt=&quot;screenshot&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/planetgen.png&quot; alt=&quot;screenshot&quot; /&gt;&lt;/p&gt;</content><author><name></name></author><summary type="html">I put together a little planet generator a few months ago, thought I would share. The generation is based on several parameters like temperature(distance to sun), size, population etc… then it churns out these neat little pixel art planets. Pretty simple but a cool result, this was done in Unity3D.</summary></entry><entry><title type="html">Update 10: GPU Picking</title><link href="/graphics/progress/2017/03/07/update-10-gpu-picking.html" rel="alternate" type="text/html" title="Update 10: GPU Picking" /><published>2017-03-07T15:38:57+00:00</published><updated>2017-03-07T15:38:57+00:00</updated><id>/graphics/progress/2017/03/07/update-10-gpu-picking</id><content type="html" xml:base="/graphics/progress/2017/03/07/update-10-gpu-picking.html">&lt;p&gt;Urho3d has a nice method for picking objects by casting a ray through the scene octree. This works well enough for picking objects using their AABBs but it was quite slow for picking points on a mesh. The issue now is that with the new terrain generation the mesh doesn’t even exist on the CPU, so it’s not possible now anyway. I thought about doing the picking on the GPU, and because,the world position for every point on screen has already been calculated for the positions buffer the work has pretty much been done already. Urho stores these buffers as textures, so I did a minor modification to the Urho3D internals and by binding the positions texture to a framebuffer I can do a glReadPixel() to get the value under the mouse cursor.&lt;/p&gt;

&lt;p&gt;The issue with glReadPixel is that it’s super slow on some hardware, my mac was taking 10ms to get that one singular pixel. This is where ‘pixel buffer objects’ come into play. Using a PBO the call to glReadPixel is non blocking, so it won’t halt the application. Instead of reading directly into client memory the function will read values into a buffer, which you can retrieve values from later. A common set up would be to have 2+ PBO’s initiated, then alternate between reading and writing them each frame. So the data you get would be from the PBO written to on a previous frame.&lt;/p&gt;

&lt;p&gt;Unfortunately my development machine is an older macbook pro and I was having real problems getting the glReadPixels to function asynchronously. Despite binding the PBO, when reading the pixels it would still halt the application. Despite lots and lots of testing I could see no solution to this, looks like a &lt;a href=&quot;https://www.opengl.org/discussion_boards/showthread.php/176221-async-glReadPixels-on-HD3000-stalls-the-pipeline&quot;&gt;bug &lt;/a&gt;beyond my control. Very annoying, however I was able to gain some performance by placing the glReadPixel before the scene is rendered. The way opengl works is that it won’t read the pixels until every other opengl call has been executed. This was a large part of why it was so slow before. Also by using a 32bit float for the texture instead of 16 bit half float seemed to help as well. I was able to take the performance to under a millisecond, however it seems to spike randomly, taking 5 to 10ms every 10th frame or so. On better hardware with proper PBO support it shouldn’t be any issue.&lt;/p&gt;

&lt;p&gt;I’ve set up my shaders so they write an object ID into the alpha channel of the positions buffer. So figuring out the type of object under the mouse is easy. The idea is that I would use that ID to cull objects from a CPU side raycast.&lt;/p&gt;

&lt;p&gt;Here you can see the results, I am now able to use the mouse to draw onto the terrain in real time. Converting grass tiles into sand tiles.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/screenshot_sun_mar__5_14_24_19_2017.png&quot; alt=&quot;screenshot&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/screenshot_sun_mar__5_14_24_50_2017.png&quot; alt=&quot;screenshot&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/screenshot_sun_mar__5_14_25_20_2017.png&quot; alt=&quot;screenshot&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Here is some good reading on PBO’s:
&lt;a href=&quot;http://http.download.nvidia.com/developer/Papers/2005/Fast_Texture_Transfers/Fast_Texture_Transfers.pdf&quot;&gt;http://http.download.nvidia.com/developer/Papers/2005/Fast_Texture_Transfers/Fast_Texture_Transfers.pdf&lt;/a&gt;
&lt;a href=&quot;https://www.seas.upenn.edu/~pcozzi/OpenGLInsights/OpenGLInsights-AsynchronousBufferTransfers.pdf&quot;&gt;https://www.seas.upenn.edu/~pcozzi/OpenGLInsights/OpenGLInsights-AsynchronousBufferTransfers.pdf&lt;/a&gt;&lt;/p&gt;</content><author><name></name></author><category term="opengl" /><category term="programming" /><category term="terrain" /><summary type="html">Urho3d has a nice method for picking objects by casting a ray through the scene octree. This works well enough for picking objects using their AABBs but it was quite slow for picking points on a mesh. The issue now is that with the new terrain generation the mesh doesn’t even exist on the CPU, so it’s not possible now anyway. I thought about doing the picking on the GPU, and because,the world position for every point on screen has already been calculated for the positions buffer the work has pretty much been done already. Urho stores these buffers as textures, so I did a minor modification to the Urho3D internals and by binding the positions texture to a framebuffer I can do a glReadPixel() to get the value under the mouse cursor.</summary></entry></feed>